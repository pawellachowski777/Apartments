{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adverts(pages=1):\n",
    "    \n",
    "    import bs4\n",
    "    from urllib.request import urlopen \n",
    "    from bs4 import BeautifulSoup as soup \n",
    "    import pandas as pd\n",
    "    \n",
    "    my_url = 'https://www.olx.pl/nieruchomosci/mieszkania/wynajem/warszawa/'\n",
    "    links = []\n",
    "    base = []\n",
    "\n",
    "    for i in range(pages+1):\n",
    "        \n",
    "        if pages == 0:\n",
    "            break\n",
    "            \n",
    "        elif i >= 1:\n",
    "            url = my_url + '?page=' + str(i)\n",
    "            uClient = urlopen(url)\n",
    "            page_html = uClient.read()\n",
    "            page_soup = soup(page_html, 'html.parser')\n",
    "            containers = page_soup.find_all('tr', {'class' : 'wrap'})\n",
    "            for cont in containers:\n",
    "                link = cont.tr.td.a['href']\n",
    "                if 'olx' in link:\n",
    "                    links.append(link)\n",
    "                    \n",
    "    rows = []\n",
    "    for link in list(set(links)):\n",
    "        try:\n",
    "            ad = urlopen(link).read()\n",
    "            ad_soup = soup(ad)\n",
    "            \n",
    "            added_class = ad_soup.find_all('li', {'class':'offer-bottombar__item'})\n",
    "            added = added_class[0].text.strip().split(', ')[1]\n",
    "            \n",
    "            localization_class = ad_soup.find_all('div', {'class':'offer-user__address'})\n",
    "            city = localization_class[0].text.split()[0]\n",
    "            district = localization_class[0].text.split()[2]\n",
    "\n",
    "            price_class = ad_soup.find_all('div', {'class':'pricelabel'})\n",
    "            price = price_class[0].text.strip().split('\\n')[0]\n",
    "            price = int(price.replace(' ', '').replace('zł',''))\n",
    "\n",
    "            by_class = ad_soup.find_all('ul', {'class':'offer-details'})\n",
    "            by = by_class[0].a.strong.text\n",
    "\n",
    "            level_class = ad_soup.find_all('li', {'class':'offer-details__item'})\n",
    "            level = level_class[1].a.text.strip().split('\\n')[1]\n",
    "\n",
    "            furniture_class = ad_soup.find_all('li', {'class':'offer-details__item'})\n",
    "            furniture = furniture_class[2].a.text.strip().replace('\\n', ' ').split()[1]\n",
    "            furniture\n",
    "            if furniture == 'Tak':\n",
    "                furniture = 1\n",
    "            else:\n",
    "                furniture = 0\n",
    "\n",
    "            building_class = ad_soup.find_all('li', {'class':'offer-details__item'})\n",
    "            building = building_class[3].a.text.split()[2]\n",
    "\n",
    "            surface_class = ad_soup.find_all('li', {'class':'offer-details__item'})\n",
    "            surface = int(surface_class[4].text.strip().replace('\\n', ' ').split()[1])\n",
    "\n",
    "            rooms_class = ad_soup.find_all('li', {'class':'offer-details__item'})\n",
    "            rooms = rooms_class[5].text.strip().replace('\\n', ' ').split()[2]\n",
    "\n",
    "            rent_class = ad_soup.find_all('li', {'class':'offer-details__item'})\n",
    "            rent = int(rent_class[6].text.strip().replace('\\n', ' ').split()[2])\n",
    "            \n",
    "            rows.append([link, city, district, price, by, level, furniture, \n",
    "                         building, surface, rooms, rent])\n",
    "        except Exception:\n",
    "            pass\n",
    "    print('pobrano dane z', len(rows), 'ogłoszeń.')\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "print(now.strftime('%d/%m/%Y %H:%M:%S'))\n",
    "\n",
    "rows = adverts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def append_df_to_excel(filename, df, sheet_name='Sheet1', startrow=None,\n",
    "                       truncate_sheet=False, \n",
    "                       **to_excel_kwargs):\n",
    "    \"\"\"\n",
    "    Append a DataFrame [df] to existing Excel file [filename]\n",
    "    into [sheet_name] Sheet.\n",
    "    If [filename] doesn't exist, then this function will create it.\n",
    "\n",
    "    Parameters:\n",
    "      filename : File path or existing ExcelWriter\n",
    "                 (Example: '/path/to/file.xlsx')\n",
    "      df : dataframe to save to workbook\n",
    "      sheet_name : Name of sheet which will contain DataFrame.\n",
    "                   (default: 'Sheet1')\n",
    "      startrow : upper left cell row to dump data frame.\n",
    "                 Per default (startrow=None) calculate the last row\n",
    "                 in the existing DF and write to the next row...\n",
    "      truncate_sheet : truncate (remove and recreate) [sheet_name]\n",
    "                       before writing DataFrame to Excel file\n",
    "      to_excel_kwargs : arguments which will be passed to `DataFrame.to_excel()`\n",
    "                        [can be dictionary]\n",
    "\n",
    "    Returns: None\n",
    "\n",
    "    (c) [MaxU](https://stackoverflow.com/users/5741205/maxu?tab=profile)\n",
    "    \"\"\"\n",
    "    from openpyxl import load_workbook\n",
    "\n",
    "    # ignore [engine] parameter if it was passed\n",
    "    if 'engine' in to_excel_kwargs:\n",
    "        to_excel_kwargs.pop('engine')\n",
    "\n",
    "    writer = pd.ExcelWriter(filename, engine='openpyxl')\n",
    "\n",
    "    # Python 2.x: define [FileNotFoundError] exception if it doesn't exist \n",
    "    try:\n",
    "        FileNotFoundError\n",
    "    except NameError:\n",
    "        FileNotFoundError = IOError\n",
    "\n",
    "\n",
    "    try:\n",
    "        # try to open an existing workbook\n",
    "        writer.book = load_workbook(filename)\n",
    "        \n",
    "        # get the last row in the existing Excel sheet\n",
    "        # if it was not specified explicitly\n",
    "        if startrow is None and sheet_name in writer.book.sheetnames:\n",
    "            startrow = writer.book[sheet_name].max_row\n",
    "\n",
    "        # truncate sheet\n",
    "        if truncate_sheet and sheet_name in writer.book.sheetnames:\n",
    "            # index of [sheet_name] sheet\n",
    "            idx = writer.book.sheetnames.index(sheet_name)\n",
    "            # remove [sheet_name]\n",
    "            writer.book.remove(writer.book.worksheets[idx])\n",
    "            # create an empty sheet [sheet_name] using old index\n",
    "            writer.book.create_sheet(sheet_name, idx)\n",
    "        \n",
    "        # copy existing sheets\n",
    "        writer.sheets = {ws.title:ws for ws in writer.book.worksheets}\n",
    "    except FileNotFoundError:\n",
    "        # file does not exist yet, we will create it\n",
    "        pass\n",
    "\n",
    "    if startrow is None:\n",
    "        startrow = 0\n",
    "\n",
    "    # write out the new sheet\n",
    "    df.to_excel(writer, sheet_name, startrow=startrow, **to_excel_kwargs)\n",
    "\n",
    "    # save the workbook\n",
    "    writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.DataFrame(rows, \n",
    "                    columns = ['link', 'miasto', 'dzielnica', 'cena', 'od', 'poziom', \n",
    "                               'umeblowanie','zabudowa','powierzchnia', 'pokoje', 'czynsz dodatkowo'])\n",
    "    \n",
    "append_df_to_excel('excel2.xlsx', base, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nowe dzielnice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_dict = dict([('533', 'Wesoła'), ('361', 'Rembertów')])\n",
    "                      \n",
    "                    #('383', 'Wawer'), ('357', 'Wilanów'),('371', 'Ursus'), ('379', 'Praga-Północ'), ('363', 'Żoliborz')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adverts(pages=1):\n",
    "    import bs4\n",
    "    from urllib.request import urlopen \n",
    "    from bs4 import BeautifulSoup as soup \n",
    "    import pandas as pd\n",
    "\n",
    "    my_url = 'https://www.olx.pl/nieruchomosci/mieszkania/wynajem/warszawa/'\n",
    "    links = []\n",
    "    rows = []\n",
    "    base = []\n",
    "\n",
    "    for d in district_dict.keys():\n",
    "        print(district_dict[d])\n",
    "\n",
    "        for i in range(pages+1):\n",
    "            if pages == 0:\n",
    "                break\n",
    "\n",
    "            elif i >= 1:\n",
    "                url = my_url + '?search%5Bdistrict_id%5D=' + str(d) + '&page=' + str(i)\n",
    "                if str(d) in url:\n",
    "                    uClient = urlopen(url)\n",
    "                    page_html = uClient.read()\n",
    "                    page_soup = soup(page_html, 'html.parser')\n",
    "                    containers = page_soup.find_all('tr', {'class' : 'wrap'})\n",
    "                    for cont in containers:\n",
    "                        link = cont.tr.td.a['href']\n",
    "                        if 'olx' in link:\n",
    "                            links.append(link)\n",
    "\n",
    "    for link in list(set(links)):\n",
    "        try:\n",
    "            ad = urlopen(link).read()\n",
    "            ad_soup = soup(ad)\n",
    "\n",
    "            added_class = ad_soup.find_all('li', {'class':'offer-bottombar__item'})\n",
    "            added = added_class[0].text.strip().split(', ')[1]\n",
    "\n",
    "            localization_class = ad_soup.find_all('div', {'class':'offer-user__address'})\n",
    "            city = localization_class[0].text.split()[0]\n",
    "            district = localization_class[0].text.split()[2]\n",
    "\n",
    "            price_class = ad_soup.find_all('div', {'class':'pricelabel'})\n",
    "            price = price_class[0].text.strip().split('\\n')[0]\n",
    "            price = int(price.replace(' ', '').replace('zł',''))\n",
    "\n",
    "            by_class = ad_soup.find_all('ul', {'class':'offer-details'})\n",
    "            by = by_class[0].a.strong.text\n",
    "\n",
    "            level_class = ad_soup.find_all('li', {'class':'offer-details__item'})\n",
    "            level = level_class[1].a.text.strip().split('\\n')[1]\n",
    "\n",
    "            furniture_class = ad_soup.find_all('li', {'class':'offer-details__item'})\n",
    "            furniture = furniture_class[2].a.text.strip().replace('\\n', ' ').split()[1]\n",
    "            furniture\n",
    "            if furniture == 'Tak':\n",
    "                furniture = 1\n",
    "            else:\n",
    "                furniture = 0\n",
    "\n",
    "            building_class = ad_soup.find_all('li', {'class':'offer-details__item'})\n",
    "            building = building_class[3].a.text.split()[2]\n",
    "\n",
    "            surface_class = ad_soup.find_all('li', {'class':'offer-details__item'})\n",
    "            surface = int(surface_class[4].text.strip().replace('\\n', ' ').split()[1])\n",
    "\n",
    "            rooms_class = ad_soup.find_all('li', {'class':'offer-details__item'})\n",
    "            rooms = rooms_class[5].text.strip().replace('\\n', ' ').split()[2]\n",
    "\n",
    "            rent_class = ad_soup.find_all('li', {'class':'offer-details__item'})\n",
    "            rent = int(rent_class[6].text.strip().replace('\\n', ' ').split()[2])\n",
    "\n",
    "            rows.append([link, city, district, price, by, level, furniture, \n",
    "                         building, surface, rooms, rent])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    print('pobrano dane z', len(rows), 'ogłoszeń.')\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wesoła\n",
      "Rembertów\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from urllib.request import urlopen \n",
    "from bs4 import BeautifulSoup as soup \n",
    "import pandas as pd\n",
    "\n",
    "my_url = 'https://www.olx.pl/nieruchomosci/mieszkania/wynajem/warszawa/'\n",
    "links = []\n",
    "rows = []\n",
    "base = []\n",
    "pages = 1\n",
    "\n",
    "for d in district_dict.keys():\n",
    "    print(district_dict[d])\n",
    "\n",
    "    for i in range(pages+1):\n",
    "        if pages == 0:\n",
    "            break\n",
    "\n",
    "        elif i >= 1:\n",
    "            url = my_url + '?search%5Bdistrict_id%5D=' + str(d) + '&page=' + str(i)\n",
    "            if str(d) in url:\n",
    "                uClient = urlopen(url)\n",
    "                page_html = uClient.read()\n",
    "                page_soup = soup(page_html, 'html.parser')\n",
    "                containers = page_soup.find_all('tr', {'class' : 'wrap'})\n",
    "                for cont in containers:\n",
    "                    link = cont.tr.td.a['href']\n",
    "                    if 'olx' in link:\n",
    "                        links.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tak\n",
      "nie\n"
     ]
    }
   ],
   "source": [
    "for d in district_dict.keys():\n",
    "    if 'olx' in link and str(d) in link:\n",
    "        print('tak')\n",
    "    else:\n",
    "        print('nie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/11/2020 15:43:51\n",
      "Wesoła\n",
      "Rembertów\n",
      "pobrano dane z 174 ogłoszeń.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "print(now.strftime('%d/%m/%Y %H:%M:%S'))\n",
    "\n",
    "rows = adverts(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.DataFrame(rows, \n",
    "                    columns = ['link', 'miasto', 'dzielnica', 'cena', 'od', 'poziom', \n",
    "                               'umeblowanie','zabudowa','powierzchnia', 'pokoje', 'czynsz dodatkowo'])\n",
    "    \n",
    "#append_df_to_excel(filename='ogloszenia.xlsx', df=base, sheet_name='dzielnice', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wesoła            46\n",
       "Rembertów         44\n",
       "Mokotów           18\n",
       "Śródmieście       17\n",
       "Wola              10\n",
       "Praga-Południe     6\n",
       "Ursynów            6\n",
       "Żoliborz           5\n",
       "Włochy             4\n",
       "Bielany            4\n",
       "Bemowo             4\n",
       "Białołęka          3\n",
       "Ochota             3\n",
       "Targówek           2\n",
       "Praga-Północ       1\n",
       "Wawer              1\n",
       "Name: dzielnica, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base['dzielnica'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
